# Neural Image Captioning with Attention

---
Automatic Image Captioning is a very well-known problem in the area of deep learning, NLP, and Computer Vision. Given an image, the model generates a text-description of the image. The project is an experiment to compare the vanilla CNN-LSTM encoder-decoder model and the CNN-LSTM encoder-decoder with soft attention. For more information on the theory and experiment setup, check out our [Technical Report](https://github.com/karthikhegde05/Neural-Image-Captioning-with-Attention/blob/main/Technical_Report.pdf)


> The CNN-LSTM with soft-attention implementation is based on the paper [Show, Attend and Tell](https://arxiv.org/pdf/1502.03044.pdf)


----
### Collaborators:
Karthik Hegde, Jishnu V Kumar, Saad Patel, Saravan Sriram 

:point_right: Jishnu and Karthik implemented and fine-tuned different CNN architectures. \
:point_right: Karthik implemented LSTM architecture with and without soft-attention mechanism. \
:point_right: Karthik, Saad and Saravan trained and tested the architecture on different sets of hyperparameters and noted the results. \
:point_right: Code refactoring and the technical report is a contribution from Karthik.





